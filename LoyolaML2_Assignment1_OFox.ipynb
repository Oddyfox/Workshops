{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. [50 pts]\n",
    "\n",
    "In this assignment, we will use Apriori analysis to find phrases, or interesting\n",
    "patterns in a novel.\n",
    "Use the <code>nltk</code> library corpus <code>gutenberg</code> API and load the novel 'carroll-alice.txt' which is the\n",
    "Alice in Wonderland by L. Carroll. There are 1703 sentences in the novel which can be\n",
    "represented as 1703 transactions. Use any means to parse/extract words and save in CSV\n",
    "format to be read by Weka framework similar to the Apriori Analysis module.\n",
    "Hint: Removing stop words and using regular expressions can be helpful:\n",
    "\n",
    "<code>from nltk.corpus import gutenberg, stopwords\n",
    "Stop_words = stopwords.words('english')\n",
    "Sentences = gutenberg.sents('carroll-alice.txt')\n",
    "TermsSentences = []\n",
    "for terms in Sentences:\n",
    "     terms = [w for w in terms if w not in Stop_words]\n",
    "     terms = [w for w in terms if re.search(r'^[a-zA-Z]{2}', w) is not None]</code>\n",
    " \n",
    "Use FPGrowth and start with default parameters. Reduce lowerBoundMinSupport to reach\n",
    "to a sweet point for the support and avoid exploding the number of rules generated.\n",
    "Report interesting patterns.\n",
    "(Example: Some of the frequently occurring phrases are Mock Turtle, White Rabbit, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the novel corpus\n",
    "from nltk.corpus import gutenberg, stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load stopwords, novel text, run RegEx on novel sentences\n",
    "Stop_words = stopwords.words('english')\n",
    "Sentences = gutenberg.sents('carroll-alice.txt')\n",
    "\n",
    "# Sentences is a list of lists. The nested lists contain the strings/words of each sentence\n",
    "# len( Sentences ) = 1703"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through the list of strings running against RegEx and Stop_words\n",
    "\n",
    "# Initialize a list to hold the processed lists of strings (This replaces Sentences)\n",
    "TermsSentences = [ ]\n",
    "\n",
    "for terms in Sentences:\n",
    "    terms = [w for w in terms if w not in Stop_words]\n",
    "    terms = [w for w in terms if re.search(r'^[a-zA-Z]{2}', w) is not None]\n",
    "    TermsSentences.append( terms )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import FPGrowth implementation so we can avoid Weka\n",
    "# !conda install -c conda-forge mlxtend\n",
    "from mlxtend.frequent_patterns import fpgrowth\n",
    "from mlxtend.preprocessing import TransactionEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform TermsSentences which is a nested list of strings into a one-hot enconded dataframe\n",
    "\n",
    "te = TransactionEncoder( )\n",
    "te_ary = te.fit( TermsSentences ).transform( TermsSentences )\n",
    "df = pd.DataFrame( te_ary, columns = te.columns_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALICE</th>\n",
       "      <th>ALL</th>\n",
       "      <th>AND</th>\n",
       "      <th>ARE</th>\n",
       "      <th>AT</th>\n",
       "      <th>Ada</th>\n",
       "      <th>Adventures</th>\n",
       "      <th>Advice</th>\n",
       "      <th>After</th>\n",
       "      <th>Ah</th>\n",
       "      <th>...</th>\n",
       "      <th>years</th>\n",
       "      <th>yelled</th>\n",
       "      <th>yelp</th>\n",
       "      <th>yer</th>\n",
       "      <th>yes</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yet</th>\n",
       "      <th>young</th>\n",
       "      <th>youth</th>\n",
       "      <th>zigzag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1698</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1699</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1701</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1702</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1703 rows × 2793 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ALICE    ALL    AND    ARE     AT    Ada  Adventures  Advice  After  \\\n",
       "0     False  False  False  False  False  False        True   False  False   \n",
       "1     False  False  False  False  False  False       False   False  False   \n",
       "2     False  False  False  False  False  False       False   False  False   \n",
       "3     False  False  False  False  False  False       False   False  False   \n",
       "4     False  False  False  False  False  False       False   False  False   \n",
       "...     ...    ...    ...    ...    ...    ...         ...     ...    ...   \n",
       "1698  False  False  False  False  False  False        True   False  False   \n",
       "1699  False  False  False  False  False  False       False   False  False   \n",
       "1700  False  False  False  False  False  False       False   False  False   \n",
       "1701  False  False  False  False  False  False       False   False  False   \n",
       "1702  False  False  False  False  False  False       False   False  False   \n",
       "\n",
       "         Ah  ...  years  yelled   yelp    yer    yes  yesterday    yet  young  \\\n",
       "0     False  ...  False   False  False  False  False      False  False  False   \n",
       "1     False  ...  False   False  False  False  False      False  False  False   \n",
       "2     False  ...  False   False  False  False  False      False  False  False   \n",
       "3     False  ...  False   False  False  False  False      False  False  False   \n",
       "4     False  ...  False   False  False  False  False      False  False  False   \n",
       "...     ...  ...    ...     ...    ...    ...    ...        ...    ...    ...   \n",
       "1698  False  ...  False   False  False  False  False      False  False  False   \n",
       "1699  False  ...  False   False  False  False  False      False  False  False   \n",
       "1700  False  ...  False   False  False  False  False      False  False  False   \n",
       "1701  False  ...  False   False  False  False  False      False  False  False   \n",
       "1702  False  ...   True   False  False  False  False      False  False  False   \n",
       "\n",
       "      youth  zigzag  \n",
       "0     False   False  \n",
       "1     False   False  \n",
       "2     False   False  \n",
       "3     False   False  \n",
       "4     False   False  \n",
       "...     ...     ...  \n",
       "1698  False   False  \n",
       "1699  False   False  \n",
       "1700  False   False  \n",
       "1701  False   False  \n",
       "1702  False   False  \n",
       "\n",
       "[1703 rows x 2793 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at results\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemsets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.011157</td>\n",
       "      <td>(get, Alice)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>131</td>\n",
       "      <td>0.017029</td>\n",
       "      <td>(could, Alice)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132</td>\n",
       "      <td>0.014093</td>\n",
       "      <td>(Alice, would)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>133</td>\n",
       "      <td>0.011744</td>\n",
       "      <td>(would, said)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134</td>\n",
       "      <td>0.012918</td>\n",
       "      <td>(Rabbit, White)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>0.012918</td>\n",
       "      <td>(say, Alice)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>136</td>\n",
       "      <td>0.013506</td>\n",
       "      <td>(way, Alice)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>137</td>\n",
       "      <td>0.016442</td>\n",
       "      <td>(much, Alice)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138</td>\n",
       "      <td>0.011744</td>\n",
       "      <td>(much, said)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>139</td>\n",
       "      <td>0.012331</td>\n",
       "      <td>(think, Alice)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.011744</td>\n",
       "      <td>(time, Alice)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>141</td>\n",
       "      <td>0.012918</td>\n",
       "      <td>(see, Alice)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>142</td>\n",
       "      <td>0.014093</td>\n",
       "      <td>(quite, Alice)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>143</td>\n",
       "      <td>0.013506</td>\n",
       "      <td>(looked, Alice)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>144</td>\n",
       "      <td>0.015854</td>\n",
       "      <td>(went, Alice)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>0.019378</td>\n",
       "      <td>(Alice, like)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146</td>\n",
       "      <td>0.012331</td>\n",
       "      <td>(like, said)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147</td>\n",
       "      <td>0.012331</td>\n",
       "      <td>(Alice, one)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148</td>\n",
       "      <td>0.011744</td>\n",
       "      <td>(said, one)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149</td>\n",
       "      <td>0.012331</td>\n",
       "      <td>(began, Alice)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.014093</td>\n",
       "      <td>(know, said)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>151</td>\n",
       "      <td>0.012918</td>\n",
       "      <td>(know, Alice)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>152</td>\n",
       "      <td>0.021139</td>\n",
       "      <td>(little, Alice)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>153</td>\n",
       "      <td>0.016442</td>\n",
       "      <td>(little, said)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154</td>\n",
       "      <td>0.012331</td>\n",
       "      <td>(It, said)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155</td>\n",
       "      <td>0.014093</td>\n",
       "      <td>(You, said)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>156</td>\n",
       "      <td>0.011744</td>\n",
       "      <td>(Duchess, said)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>157</td>\n",
       "      <td>0.011744</td>\n",
       "      <td>(tone, said)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>158</td>\n",
       "      <td>0.011744</td>\n",
       "      <td>(Caterpillar, said)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159</td>\n",
       "      <td>0.015267</td>\n",
       "      <td>(Queen, said)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.011157</td>\n",
       "      <td>(Cat, said)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>161</td>\n",
       "      <td>0.016442</td>\n",
       "      <td>(Hatter, said)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>162</td>\n",
       "      <td>0.017616</td>\n",
       "      <td>(Hare, March)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>163</td>\n",
       "      <td>0.024662</td>\n",
       "      <td>(King, said)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>164</td>\n",
       "      <td>0.018790</td>\n",
       "      <td>(Turtle, said)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165</td>\n",
       "      <td>0.032883</td>\n",
       "      <td>(Mock, Turtle)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>166</td>\n",
       "      <td>0.018790</td>\n",
       "      <td>(Mock, said)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>167</td>\n",
       "      <td>0.012331</td>\n",
       "      <td>(Gryphon, said)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      support             itemsets\n",
       "130  0.011157         (get, Alice)\n",
       "131  0.017029       (could, Alice)\n",
       "132  0.014093       (Alice, would)\n",
       "133  0.011744        (would, said)\n",
       "134  0.012918      (Rabbit, White)\n",
       "135  0.012918         (say, Alice)\n",
       "136  0.013506         (way, Alice)\n",
       "137  0.016442        (much, Alice)\n",
       "138  0.011744         (much, said)\n",
       "139  0.012331       (think, Alice)\n",
       "140  0.011744        (time, Alice)\n",
       "141  0.012918         (see, Alice)\n",
       "142  0.014093       (quite, Alice)\n",
       "143  0.013506      (looked, Alice)\n",
       "144  0.015854        (went, Alice)\n",
       "145  0.019378        (Alice, like)\n",
       "146  0.012331         (like, said)\n",
       "147  0.012331         (Alice, one)\n",
       "148  0.011744          (said, one)\n",
       "149  0.012331       (began, Alice)\n",
       "150  0.014093         (know, said)\n",
       "151  0.012918        (know, Alice)\n",
       "152  0.021139      (little, Alice)\n",
       "153  0.016442       (little, said)\n",
       "154  0.012331           (It, said)\n",
       "155  0.014093          (You, said)\n",
       "156  0.011744      (Duchess, said)\n",
       "157  0.011744         (tone, said)\n",
       "158  0.011744  (Caterpillar, said)\n",
       "159  0.015267        (Queen, said)\n",
       "160  0.011157          (Cat, said)\n",
       "161  0.016442       (Hatter, said)\n",
       "162  0.017616        (Hare, March)\n",
       "163  0.024662         (King, said)\n",
       "164  0.018790       (Turtle, said)\n",
       "165  0.032883       (Mock, Turtle)\n",
       "166  0.018790         (Mock, said)\n",
       "167  0.012331      (Gryphon, said)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run fpgrowth on dataframe\n",
    "results = fpgrowth( df, min_support = 0.01, use_colnames = True, max_len = 2 )\n",
    "results[ 130 : 170 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see if 'White Rabbit' is included in the results df as suggested it should be\n",
    "\n",
    "for i in range( len( results ) ):\n",
    "    if len( results[ 'itemsets' ][ i ] ) == 2:\n",
    "        str_to_check = 'White Rabbit'\n",
    "        current_string = str( list( results[ 'itemsets' ][ i ] )[ 0 ] ) + ' ' + str( list( results[ 'itemsets' ][ i ] )[ 1 ] )\n",
    "\n",
    "        if str_to_check == current_string:\n",
    "            print( 'Index: ', i, ' ', current_string )\n",
    "            \n",
    "# Even at a min_support of 0.0005 which returns 70938 single or paired words, 'White Rabbit' is not returned as a pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. [50 pts]\n",
    "\n",
    "In the lecture module, the class <code>NeuralNetMLP</code> is a single hidden layer neural\n",
    "network implementation. Make the necessary modifications to upgrade it to a 2 hidden\n",
    "layer network. Run it on the MNIST dataset and report its performance.\n",
    "\n",
    "(Hint: Raschka, Chapter 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows= 60000, columns= 784\n",
      "Rows= 10000, columns= 784\n"
     ]
    }
   ],
   "source": [
    "# Load in the MNIST dataset\n",
    "\n",
    "def load_mnist(path, kind='train'):\n",
    "    from numpy import fromfile, uint8\n",
    "    import os\n",
    "    import struct\n",
    "    \n",
    "    labels_path = os.path.join(path, '%s-labels-idx1-ubyte' % kind)\n",
    "    images_path = os.path.join(path, '%s-images-idx3-ubyte' % kind)\n",
    "    with open(labels_path, 'rb') as lbpath:\n",
    "        magic, n = struct.unpack('>II', lbpath.read(8))\n",
    "        labels = fromfile(lbpath, dtype=uint8)\n",
    "        with open(images_path, 'rb') as imgpath:\n",
    "            magic, num, rows, cols = struct.unpack(\">IIII\",imgpath.read(16))\n",
    "            images = fromfile(imgpath, dtype=uint8).reshape(len(labels), 784)\n",
    "            images = ((images / 255.) - .5) * 2\n",
    "    return images, labels\n",
    "\n",
    "X_train, y_train = load_mnist('mnist/', kind='train')\n",
    "print(f'Rows= {X_train.shape[0]}, columns= {X_train.shape[1]}')\n",
    "\n",
    "X_test, y_test = load_mnist('mnist/', kind='t10k')\n",
    "print(f'Rows= {X_test.shape[0]}, columns= {X_test.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the MLP Class\n",
    "\n",
    "class NeuralNetMLP( object ):\n",
    "    \n",
    "    def __init__( self, n_hidden = 30, epochs = 100, eta = 0.0001, minibatch_size = 100, seed = None ):\n",
    "        self.random = np.random.RandomState( seed )\n",
    "        self.n_hidden = n_hidden\n",
    "        self.epochs = epochs\n",
    "        self.eta = eta\n",
    "        self.minibatch_size = minibatch_size\n",
    "        \n",
    "    @staticmethod\n",
    "    def onehot( y, n_classes ):\n",
    "        onehot = np.zeros( ( n_classes, y.shape[ 0 ] ) )\n",
    "        for idx, val in enumerate( y.astype( int ) ):\n",
    "            onehot[ val, idx ] = 1.0\n",
    "        return( onehot.T )\n",
    "    \n",
    "    @staticmethod\n",
    "    def sigmoid( z ):\n",
    "        return( 1.0 / ( 1.0 + np.exp( -np.clip( z, -250, 250 ) ) ) )\n",
    "    \n",
    "    def _forward( self, X ): \n",
    "        # Equation 2\n",
    "        z_h1 = np.dot( X, self.w_h1 )\n",
    "        a_h1 = self.sigmoid( z_h1 )\n",
    "        \n",
    "        z_h2 = np.dot( a_h1, self.w_h2 )\n",
    "        a_h2 = self.sigmoid( z_h2 )\n",
    "        \n",
    "        z_out = np.dot( a_h2, self.w_out )\n",
    "        a_out = self.sigmoid( z_out )\n",
    "        \n",
    "        return( z_h1, a_h1, z_h2, a_h2, z_out, a_out )\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_cost( y_enc, output ):\n",
    "        term1 = -y_enc * ( np.log( output ) )\n",
    "        term2 = ( 1.0 - y_enc ) * np.log( 1.0 - output )\n",
    "        cost = np.sum( term1 - term2 )\n",
    "        return( cost )\n",
    "    \n",
    "    def predict( self, X ):\n",
    "        z_h1, a_h1, z_h2, a_h2, z_out, a_out = self._forward( X )\n",
    "        y_pred = np.argmax( z_out, axis = 1 )\n",
    "        return( y_pred )\n",
    "    \n",
    "    def fit( self, X_train, y_train, X_valid, y_valid ):\n",
    "        import sys\n",
    "        \n",
    "        n_output = np.unique( y_train ).shape[ 0 ]\n",
    "        n_features = X_train.shape[ 1 ]\n",
    "        \n",
    "        self.w_out = self.random.normal( loc = 0.0, scale = 0.1, size = ( self.n_hidden, n_output ) )\n",
    "        \n",
    "        self.w_h1 = self.random.normal( loc = 0.0, scale = 0.1, size = ( n_features, self.n_hidden ) )\n",
    "        self.w_h2 = self.random.normal( loc = 0.0, scale = 0.1, size = ( self.n_hidden, self.n_hidden ) )\n",
    "        \n",
    "        y_train_enc = self.onehot( y_train, n_output )\n",
    "        \n",
    "        for i in range( self.epochs ):\n",
    "            indices = np.arange( X_train.shape[ 0 ] )\n",
    "            \n",
    "            for start_idx in range( 0, indices.shape[ 0 ] - self.minibatch_size + 1, self.minibatch_size ):\n",
    "                batch_idx = indices[ start_idx : start_idx + self.minibatch_size ]\n",
    "                \n",
    "                z_h1, a_h1, z_h2, a_h2, z_out, a_out = self._forward( X_train[ batch_idx ] )\n",
    "                \n",
    "                # Equation 3\n",
    "                sigmoid_derivative_ah1 = a_h1 * ( 1.0 - a_h1 )\n",
    "                sigmoid_derivative_ah2 = a_h2 * ( 1.0 - a_h2 )\n",
    "                \n",
    "                # Equation 5\n",
    "                delta_out = a_out - y_train_enc[ batch_idx ]\n",
    "                \n",
    "                # Equation 6 \n",
    "                delta_h2 = ( np.dot( delta_out, self.w_out.T ) * sigmoid_derivative_ah2 )\n",
    "                delta_h1 = ( np.dot( delta_h2, self.w_h2.T ) * sigmoid_derivative_ah1 )\n",
    "                \n",
    "                # Equation 7\n",
    "                grad_w_out = np.dot( a_h2.T, delta_out )\n",
    "                \n",
    "                # Equation 8\n",
    "                grad_w_h2 = np.dot( a_h1.T, delta_h2 )\n",
    "                grad_w_h1 = np.dot( X_train[ batch_idx ].T, delta_h1 )\n",
    "                \n",
    "                # Equation 9\n",
    "                self.w_out -= self.eta * grad_w_out\n",
    "                \n",
    "                self.w_h1 -= self.eta * grad_w_h1\n",
    "                self.w_h2 -= self.eta * grad_w_h2\n",
    "                \n",
    "                \n",
    "            # Evaluation after each epoch during training\n",
    "            z_h1, a_h1, z_h2, a_h2, z_out, a_out = self._forward( X_train )\n",
    "            \n",
    "            cost = self.compute_cost( y_enc = y_train_enc, output = a_out )\n",
    "            y_train_pred = self.predict( X_train )  # monitoring training progress through reclassification\n",
    "            y_valid_pred = self.predict( X_valid )  # monitoring training progress through validation\n",
    "            train_acc = ( ( np.sum( y_train == y_train_pred ) ).astype( float ) / X_train.shape[ 0 ] )\n",
    "            valid_acc = ( ( np.sum( y_valid == y_valid_pred ) ).astype( float ) / X_valid.shape[ 0 ] )\n",
    "            sys.stderr.write( '\\r%d/%d | Cost: %.2f ' '| Train/Valid Acc.: %.2f%%/%.2f%% '%\n",
    "                ( i+1, self.epochs, cost, train_acc * 100, valid_acc * 100 ) )\n",
    "            sys.stderr.flush( )\n",
    "            \n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "300/300 | Cost: 7849.39 | Train/Valid Acc.: 98.05%/95.74%  "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.NeuralNetMLP at 0x1984fdaaec8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define and fit the neural network\n",
    "nn = NeuralNetMLP( n_hidden = 20, epochs = 300, eta = 0.0005, minibatch_size = 100, seed = 1 )\n",
    "\n",
    "nn.fit( X_train = X_train[ : 55000 ], y_train = y_train[ : 55000 ], X_valid = X_train[ 55000 : ], y_valid = y_train[ 55000 : ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
