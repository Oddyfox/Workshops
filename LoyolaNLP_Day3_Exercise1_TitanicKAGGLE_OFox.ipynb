{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Locate and load the data file\n",
    "df = pd.read_csv('titanic_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfX = df.loc[:, df.columns != 'Survived']\n",
    "dfy = df.loc[:, df.columns == 'Survived'].values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dfX.values\n",
    "y = dfy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 10-fold CV evaluation of a classifier\n",
    "def eval_classifier(_clf, _X, _y):\n",
    "    acc = []\n",
    "    kf = StratifiedKFold(n_splits=10, shuffle=False, random_state=None)\n",
    "    for train_index, test_index in kf.split(_X, _y):\n",
    "        _clf.fit(_X[train_index], _y[train_index])\n",
    "        y_pred = _clf.predict(_X[test_index])\n",
    "        acc += [accuracy_score(_y[test_index], y_pred)]\n",
    "    return np.array(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = np.unique(y, return_counts=True)\n",
    "NBpriors = [counts[1][0]/len(y), counts[1][1]/len(y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes CV accuracy=0.45 ±0.018\n",
      "Random Forest CV accuracy=0.83 ±0.032\n"
     ]
    }
   ],
   "source": [
    "acc = eval_classifier(GaussianNB(priors=NBpriors), X, y)\n",
    "print(f'Naive Bayes CV accuracy={np.mean(acc):.2f} {chr(177)}{np.std(acc):.3f}')\n",
    "\n",
    "# For reference\n",
    "acc = eval_classifier(RandomForestClassifier(n_estimators=200, max_depth=5, random_state=None, n_jobs=4), X, y)\n",
    "print(f'Random Forest CV accuracy={np.mean(acc):.2f} {chr(177)}{np.std(acc):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def weakDT_fit(_list_cols, _X, _y):\n",
    "    Xs = _X[:,_list_cols]\n",
    "    return DecisionTreeClassifier( max_depth = 2 ).fit(Xs, _y)\n",
    "\n",
    "def weakDT_predict(_clf, _list_cols, _X):\n",
    "    Xs = _X[:,_list_cols]\n",
    "    return _clf.predict(Xs), _clf.predict_proba(Xs)\n",
    "\n",
    "# Use _m features randomly selected, a total of M weak learners\n",
    "def features_randomsubset(_M, _m, nensemble=1):\n",
    "    from numpy.random import choice\n",
    "    # returns a list of list of column choices - subset features\n",
    "    return [choice(_M, _m, replace=False) for _ in range(nensemble)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total #results=1000\n",
      "Weak learners average Acc= 0.67 ±0.064\n",
      "Wall time: 585 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def eval_weak(_X, _y, _nensemble, _nfeatures):\n",
    "    acc = []\n",
    "    for j in range(_nensemble):\n",
    "        # Keep subset features, columns same for a 10-fold\n",
    "        cols = features_randomsubset(_X.shape[1], _nfeatures, nensemble=1)\n",
    "        # 10-fold CV\n",
    "        kf = StratifiedKFold(n_splits=10, shuffle=False, random_state=None)\n",
    "        for train_index, test_index in kf.split(_X, _y):\n",
    "            clf = weakDT_fit(cols[0], _X[train_index], _y[train_index])\n",
    "            y_pred, y_prob = weakDT_predict(clf, cols[0], _X[test_index])\n",
    "            acc += [accuracy_score(_y[test_index], y_pred)]\n",
    "    #\n",
    "    return np.array(acc)\n",
    "    \n",
    "# Measure individual weak learners performance\n",
    "acc = eval_weak(X, y, 100, 5)\n",
    "\n",
    "# Sanity\n",
    "print(f'total #results={len(acc)}')\n",
    "\n",
    "print(f'Weak learners average Acc= {np.mean(acc):.2f} {chr(177)}{np.std(acc):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate numerous trained NB classifiers based on subset features\n",
    "def ensembleDT_fit(_ensemble_cols, _X, _y):\n",
    "    # the list of ensemble columns have a column list for every member of the ensemble\n",
    "    nensemble = len(_ensemble_cols)\n",
    "    # list of weak learners\n",
    "    ensemble_clf = []\n",
    "    for j in range(nensemble):\n",
    "        ensemble_clf += [weakDT_fit(_ensemble_cols[j], _X, _y)]\n",
    "    #\n",
    "    return ensemble_clf\n",
    "\n",
    "# Using learned ensemble predict the outcome with majority voting\n",
    "def ensembleDT_predict(_ensemble_clf, _ensemble_cols, _Xtest):\n",
    "    from collections import defaultdict\n",
    "    nensemble = len(_ensemble_clf)\n",
    "    assert nensemble==len(_ensemble_cols)  # Error check\n",
    "    # weak learner predictions\n",
    "    ypred_e, yprob_e = [], []\n",
    "    for j in range(nensemble):\n",
    "        res = weakDT_predict(_ensemble_clf[j], _ensemble_cols[j], _Xtest)\n",
    "        ypred_e += [res[0]]\n",
    "        yprob_e += [res[1]]  # score of the prediction\n",
    "    # majority voting for each data point in _Xtest\n",
    "    ypred = []\n",
    "    for i in range(_Xtest.shape[0]):\n",
    "        ypred_scores = defaultdict(float)\n",
    "        for j in range(nensemble):\n",
    "            for c, p in enumerate(yprob_e[j][i]):\n",
    "                # a proper score is necessary\n",
    "                ypred_scores[c] += p\n",
    "        ix = max(ypred_scores.items(), key=lambda a: a[1])\n",
    "        ypred += [ix[0]]\n",
    "    #\n",
    "    return np.array(ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble learners average Acc= 0.77 ±0.033\n",
      "Wall time: 9.02 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def eval_ensemble(_X, _y, _niter, _nensemble, _nfeatures):\n",
    "    acc = []\n",
    "    for i in range(_niter):\n",
    "        # Keep subset features, columns same for a 10-fold\n",
    "        cols = features_randomsubset(_X.shape[1], _nfeatures, nensemble=_nensemble)\n",
    "        # 10-fold CV\n",
    "        kf = StratifiedKFold(n_splits=10, shuffle=False, random_state=None)\n",
    "        for train_index, test_index in kf.split(_X, _y):\n",
    "            clf = ensembleDT_fit(cols, _X[train_index], _y[train_index])\n",
    "            y_pred = ensembleDT_predict(clf, cols, _X[test_index])\n",
    "            acc += [accuracy_score(_y[test_index], y_pred)]\n",
    "    #\n",
    "    return np.array(acc)\n",
    "\n",
    "# Measure ensemble weak learners performance\n",
    "acc = eval_ensemble(X, y, 10, 200, 7)\n",
    "\n",
    "print(f'Ensemble learners average Acc= {np.mean(acc):.2f} {chr(177)}{np.std(acc):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs = np.array([np.correlate(X[:,j], y)[0] for j in range(X.shape[1])])\n",
    "\n",
    "# Reverse sort, numpy array negation reverses the order\n",
    "ranks = np.argsort((-corrs))\n",
    "\n",
    "# Display top-9 and bot-5\n",
    "rankings = [(f'{corrs[j]:.1f}', df.columns[j]) for j in ranks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "delcols = [(j, f'{corrs[j]:.1f}', df.columns[j]) for j in ranks if corrs[j]<=2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column numbers to delete\n",
    "dd = [d[0] for d in delcols]\n",
    "\n",
    "# Drop those columns, axis=1\n",
    "Xpp = np.delete(np.array(X, copy=True), dd, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble learners average Acc= 0.82 ±0.027\n"
     ]
    }
   ],
   "source": [
    "acc = eval_ensemble(Xpp, y, 10, 200, 11)\n",
    "print(f'Ensemble learners average Acc= {np.mean(acc):.2f} {chr(177)}{np.std(acc):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of features\n",
    "M = Xpp.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Run an experiment for a full scale of number of features\n",
    "valsF, accF, stdevF = np.arange(1,M+1), [], []\n",
    "for nf in valsF:\n",
    "    acc = eval_ensemble(Xpp, y, 10, 200, nf)\n",
    "    accF += [np.mean(acc)]\n",
    "    stdevF += [np.std(acc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
